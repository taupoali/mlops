{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624961ac",
   "metadata": {},
   "source": [
    "# Challenge 3: Configuring and running an Amazon SageMaker Inference Recommender job\n",
    "\n",
    "In this notebook, you use SageMaker Inference Recommender, your production model, and a payload of data to find the best instance type for your endpoint.\n",
    "\n",
    "SageMaker Inference Recommender is a capability of SageMaker that reduces the time required to get machine learning (ML) models in production by automating load tests and optimizing model performance across instance types. You use Inference Recommender to select a real-time inference endpoint that delivers the best performance at the lowest cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ee3e5",
   "metadata": {},
   "source": [
    "## Task 3.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971394d-1fa6-40b7-8499-f48024354ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "%matplotlib inline\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role, session,image_uris\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'sagemaker/abalone'\n",
    "payload_archive_name = \"payload.tar.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142abd26-b77c-4e4d-9d73-3413ffd5f3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list-model-name\n",
    "models = sm.list_models(NameContains='Abalone')\n",
    "model_details = pd.json_normalize(models['Models'])\n",
    "model_name = model_details['ModelName'][0]\n",
    "print (model_name)\n",
    "#get-model-s3uri\n",
    "desc_model= sm.describe_model(ModelName=model_name)\n",
    "model_attr = pd.json_normalize(desc_model['PrimaryContainer'])\n",
    "model_url = model_attr['ModelDataUrl'][0]\n",
    "print (model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12feecd-12da-4aef-834f-38ed9e7b23a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list-endpoint-config\n",
    "endpoint_config= sm.list_endpoint_configs(NameContains='abalone')\n",
    "print (endpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b0646-89fe-4693-8e24-4b13ccdc4138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list-endpoint\n",
    "endpoint_name= sm.list_endpoints(NameContains='abalone')\n",
    "print (endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5dc1a",
   "metadata": {},
   "source": [
    "# Task 3.2: Create a payload archive\n",
    "\n",
    "In this task, you create an archive that contains individual files that Inference Recommender can send to the SageMaker endpoints. \n",
    "\n",
    "Inference Recommender randomly samples files from the created archive to ensure it contains a similar distribution of payloads that you would expect in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936bc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvzf {payload_archive_name} \"data/abalone_data_new_nolabel.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6b818-5013-4f4e-8128-10223b895289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upload-payload-archive-to-S3\n",
    "sample_payload_url = sm_session.upload_data(\n",
    "    path=payload_archive_name, key_prefix=\"payload\"\n",
    ")\n",
    "\n",
    "print (sample_payload_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23150cd1",
   "metadata": {},
   "source": [
    "## Task 3.3: Register model in Model Registry\n",
    "\n",
    "In order to use Inference Recommender, you must have a versioned model in SageMaker Model Registry. To register a model in the Model Registry, you must have a model artifact packaged in a tarball and an inference container image. \n",
    "\n",
    "Registering a model includes the following steps:\n",
    "\n",
    "- **Create Model Group**: This is a one-time task per machine learning use case. A Model Group contains one or more versions of your packaged model.\n",
    "\n",
    "- **Register Model Version/Package**: This task is performed for each new packaged model version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-image-uri\n",
    "image_uri = image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1f905",
   "metadata": {},
   "source": [
    "### Challenge: Model group configuration\n",
    "\n",
    "In the next cells, you create a model package group. What information is important to include in the model package group so you know the framework and task required?\n",
    "\n",
    "Troubleshoot the next cells until you can create the model package group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML framework details\n",
    "#framework = \"XGBOOST\"\n",
    "framework_version = \"1.5-1\"\n",
    "\n",
    "# ML model details\n",
    "ml_domain = \"MACHINE_LEARNING\"\n",
    "#ml_task = \"REGRESSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf170117-e0bd-440e-ad1b-05e1a5b2b314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create Model Group\n",
    "\n",
    "model_package_group_name = \"{}-cpu-models-\".format(framework) + str(round(time.time()))\n",
    "model_package_group_description = \"{} models\".format(ml_task.lower())\n",
    "\n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageGroupDescription\": model_package_group_description,\n",
    "}\n",
    "\n",
    "create_model_package_group_response = sm.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "print(\n",
    "    \"ModelPackageGroup ARN : {}\".format(create_model_package_group_response[\"ModelPackageGroupArn\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010d52c",
   "metadata": {},
   "source": [
    "<i class=\"far fa-eye\" style=\"color:#262262\" aria-hidden=\"true\"></i> **Hint:** Validate the missing parameters and update the **ML Framework Details** cell to declare the missing parameters and re-run the cell again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269e141",
   "metadata": {},
   "source": [
    "When the model package group creates successfully, you should see the model package group ARN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31918d54",
   "metadata": {},
   "source": [
    "### Register Model\n",
    "\n",
    "In this step, you register your model that was packaged in the prior steps as a new version in SageMaker Model Registry. \n",
    "\n",
    "First, you configure the model package and version identifying which model package group this new model should be registered within as well as identify the initial approval status. You also identify the domain and task for your model. These values were set earlier in the notebook where ml_domain = 'MACHINE_LEARNING' and ml_task = 'REGRESSION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register-model-Package\n",
    "\n",
    "model_package_description = \"{} {} inference recommender\".format(framework, model_name)\n",
    "\n",
    "model_approval_status = \"PendingManualApproval\"\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"Domain\": ml_domain.upper(),\n",
    "    \"Task\": ml_task.upper(),\n",
    "    \"SamplePayloadUrl\": sample_payload_url,\n",
    "    \"ModelPackageDescription\": model_package_description,\n",
    "    \"ModelApprovalStatus\": model_approval_status,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac8408",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3.4: Set up inference specification\n",
    "\n",
    "In this task, you set up the inference specification configuration for your model version. This contains information on how the model should be hosted.\n",
    "\n",
    "Inference Recommender expects a single input MIME type for sending requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bff2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-MIME-type\n",
    "input_mime_types = [\"text/csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed37bc2",
   "metadata": {},
   "source": [
    "Now, you specify a set of instance types. Inference Recommender provides recommendations within the set of instances you select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-inference-types\n",
    "supported_realtime_inference_types = [\n",
    "    \"ml.m5.large\",\n",
    "    \"ml.m5.xlarge\",\n",
    "    \"ml.m4.xlarge\",\n",
    "    \"ml.m5.2xlarge\",\n",
    "    \"ml.m5.4xlarge\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef35676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-inference-specification\n",
    "modelpackage_inference_specification = {\n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": image_uri,\n",
    "                \"Framework\": framework.upper(),\n",
    "                \"FrameworkVersion\": framework_version,\n",
    "                \"NearestModelName\": model_name,\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedContentTypes\": input_mime_types,  # required, must be non-null\n",
    "        \"SupportedResponseMIMETypes\": [],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": supported_realtime_inference_types,  # optional\n",
    "    }\n",
    "}\n",
    "\n",
    "# Specify the model data\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\n",
    "    \"ModelDataUrl\"\n",
    "] = model_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67726ba0",
   "metadata": {},
   "source": [
    "Now that you configured the model package, the next step is to create the model package/version in SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-model-package\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef7acd-ddb1-4849-bd7f-8655f599d448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_mode_package_response = sm.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "print(\"ModelPackage Version ARN : {}\".format(model_package_arn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2a415",
   "metadata": {},
   "source": [
    "## Task 3.5: Create an Inference Recommender Default Job\n",
    "\n",
    "Now the model is registered in Model Registry, you run a 'Default' job to get instance recommendations. \n",
    "\n",
    "This job requires the ModelPackageVersionArn and comes back with recommendations within **45** minutes.\n",
    "\n",
    "The output is a list of instance type recommendations with associated *environment variables*, *cost*, *throughput* and *latency metrics*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53ef5b-cb3d-4a34-81c3-67446f9355e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set-job-name-job-type\n",
    "job_name = model_name + \"-instance-\" + str(round(time.time()))\n",
    "job_description = \"{} {}\".format(framework, model_name)\n",
    "job_type = \"Default\"\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eb895-38b1-4949-9ee8-a56a5b323687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-inference-recommendation-job\n",
    "response = sm.create_inference_recommendations_job(\n",
    "    JobName=job_name,\n",
    "    JobDescription=job_description,  # optional\n",
    "    JobType=job_type,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\"ModelPackageVersionArn\": model_package_arn},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95133e6f",
   "metadata": {},
   "source": [
    "## Task 3.6: Instance Recommendation Results\n",
    "\n",
    "Each inference recommendation includes InstanceType, InitialInstanceCount, EnvironmentParameters which are tuned environment variable parameters for better performance and also includes performance metrics such as CpuUtilization, MemoryUtilization and cost metrics such as MaxInvocations, ModelLatency, CostPerHour and CostPerInference. \n",
    "\n",
    "These metrics may help to narrow down to a specific endpoint configuration that suits your use case best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea48fbf",
   "metadata": {},
   "source": [
    "Since the execution of the inference recommender job you started above does not finish for **45** minutes, view a inference recommendations report from a file that was generated and pre-loaded from an earlier Inference Recommender job run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('data/inference_recommendations.csv')\n",
    "pd.set_option(\"max_colwidth\", 400)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f9aa1",
   "metadata": {},
   "source": [
    "Notice that the five instances you included in the *supported_realtime_inference_types* list are included in the Inference Recommender job results. \n",
    "\n",
    "Which instance has the smallest *CostPerHour* value?\n",
    "\n",
    "The **ml.m5.large** instance has the smallest *CostPerHour* value.\n",
    "\n",
    "Which instance has the lowest *ModelLatency*?\n",
    "\n",
    "The **ml.m5.4xlarge** instance has the lowest *ModelLatency*.\n",
    "\n",
    "Take a moment to review the other columns and values for each instance.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** You can continue to **Challenge 4** while you are waiting for the Inference Recommender job to complete. You can also monitor the Inference Recommender job status in the SageMaker console under the Inference tab.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\" aria-hidden=\"true\"></i> **Note:** The Inference Recommender job takes approximately *45* minutes to generate a report. After **Challenge 4** is complete, you can come back and wait for the job to complete if you want to review the job results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccf54e-a6bc-42ee-95a6-8e86bdf93c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optional: get-inference-recommender-job-status\n",
    "finished = False\n",
    "while not finished:\n",
    "    inference_recommender_job = sm.describe_inference_recommendations_job(JobName=job_name)\n",
    "    if inference_recommender_job[\"Status\"] in [\"COMPLETED\", \"STOPPED\", \"FAILED\"]:\n",
    "        finished = True\n",
    "    else:\n",
    "        print(\"In progress\")\n",
    "        time.sleep(300)\n",
    "\n",
    "if inference_recommender_job[\"Status\"] == \"FAILED\":\n",
    "    print(\"Inference recommender job failed \")\n",
    "    print(\"Failed Reason: {}\",inference_recommender_job[\"FailureReason\"])\n",
    "else:\n",
    "    print(\"Inference recommender job completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25385613-99ce-4cee-af61-e19e9cb627fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optional: print-inference-recommender-job-results\n",
    "data = [\n",
    "    {**x[\"EndpointConfiguration\"], **x[\"ModelConfiguration\"], **x[\"Metrics\"]}\n",
    "    for x in inference_recommender_job[\"InferenceRecommendations\"]\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "dropFilter = df.filter([\"VariantName\"])\n",
    "df.drop(dropFilter, inplace=True, axis=1)\n",
    "pd.set_option(\"max_colwidth\", 400)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48162cf5",
   "metadata": {},
   "source": [
    "In this notebook, you learned how to use SageMaker Inference Recommender with an XGBoost model to help determine the right CPU instance to reduce costs and maximize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278d35e",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "When you have completed this notebook and viewed the Inference Recommender job results, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with **Challenge 4**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
