{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4: SageMaker Model Monitoring misconfiguration\n",
    "\n",
    "In this notebook, you identify issues with the implementation of SageMaker Model Monitoring with a production model and endpoint. Next, you troubleshoot an Amazon CloudWatch alarm. Then, you troubleshoot an automated solution that retrains the model if there is model drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Uploader,S3Downloader\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from time import sleep\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from threading import Thread\n",
    "import random\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'sagemaker/abalone'\n",
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "#Available Capture Modes - Input, Output\n",
    "#capture_modes = [ \"Input\",  \"Output\" ]\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list-model\n",
    "models = sm.list_models(NameContains='abalone',SortOrder='Ascending')\n",
    "model_details = pd.json_normalize(models['Models'])\n",
    "model_name = model_details['ModelName'][0]\n",
    "print (model_name)\n",
    "\n",
    "#model-s3-uri\n",
    "desc_model= sm.describe_model(ModelName=model_name)\n",
    "model_attr = pd.json_normalize(desc_model['PrimaryContainer'])\n",
    "model_url = model_attr['ModelDataUrl'][0]\n",
    "print (model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: Create a production endpoint config with Data Capture enabled\n",
    "\n",
    "To log the inputs to your endpoint and the inference outputs from your deployed model to Amazon S3, you can enable a feature called Data Capture. Data Capture records information that can be used for training, debugging, and monitoring. Amazon SageMaker Model Monitor automatically parses this captured data and compares metrics from this data with a baseline that you create for the model.\n",
    "\n",
    "In this task, you create a new endpoint config to enable data capture for monitoring model data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Define the data capture configuration\n",
    "\n",
    "You can capture the request payload, the response payload, or both with this configuration. The capture config applies to all variants.\n",
    "\n",
    "There is an issue with this current endpoint configuration. The capture modes are missing from the variables the data scientist team expected to set up. Find the error and address it by creating the correct variable.\n",
    "\n",
    "\n",
    "<i class=\"fas fa-info-circle\" style=\"color:#008296\"></i> **Learn more:** Refer to [CreateEndpointConfig](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpointConfig.html) for more information about how to correctly set up  an endpoint configuration.\n",
    "\n",
    "<i class=\"fas fa-info-circle\" style=\"color:#008296\"></i> **Learn more:** Refer to [DataCaptureConfig](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DataCaptureConfig.html) for more information about how to correctly set up a data capture configuration within an endpoint configuration.\n",
    "\n",
    "<i class=\"fas fa-info-circle\" style=\"color:#008296\"></i> **Learn more:** Refer to [CaptureOption](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CaptureOption.html) for more information about which values are valid for a *CaptureOption*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-endpoint-configuration\n",
    "variant_name = 'AllTraffic'\n",
    "endpoint_config_name = f'Abalone-Endpoint-1-{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'ModelName':model_name,\n",
    "            'InstanceType':'ml.t2.large',\n",
    "            'InitialInstanceCount':1,\n",
    "            'VariantName':variant_name\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "        DataCaptureConfig= {\n",
    "        'EnableCapture': True, # Whether data should be captured or not.\n",
    "        'InitialSamplingPercentage' : 100,\n",
    "        'CaptureContentTypeHeader': {'CsvContentTypes': [ 'text/csv' ]},\n",
    "        'DestinationS3Uri': s3_capture_upload_path,\n",
    "        'CaptureOptions': [{\"CaptureMode\" : capture_mode} for capture_mode in capture_modes] # Example - Use list comprehension to capture both Input and Output\n",
    "    }\n",
    ")\n",
    "print(f\"Created the Production Model Endpoint Config: {endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"far fa-eye\" style=\"color:#262262\" aria-hidden=\"true\"></i> **Hint:** Declare the **capture_modes** to capture both the Input and Output in the endpoint DataCapture configuration and re-run the prior cell.\n",
    "\n",
    "<i class=\"fas fa-flag-checkered\"></i> **Answer:** Add this variable before the endpoint configuration is set to define the capture modes.\n",
    "\n",
    "`capture_modes = [ \"Input\",  \"Output\" ]`\n",
    "\n",
    "After the challenge is complete, list the endpoint and update the endpoint with the new endpoint configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list-endpoint\n",
    "endpoints= sm.list_endpoints(NameContains='abalone',SortOrder='Ascending')\n",
    "endpoint_details = pd.json_normalize(endpoints['Endpoints'])\n",
    "endpoint_name = endpoint_details['EndpointName'][0]\n",
    "print (endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** Endpoint update takes approximately 5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#update-endpoint\n",
    "endpoint_response = sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))\n",
    "\n",
    "def wait_for_endpoint_update_complete(endpoint):\n",
    "    \"\"\"Helper function to wait for the completion of updating an endpoint\"\"\"\n",
    "    response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response.get(\"EndpointStatus\")\n",
    "    while status == \"Updating\":\n",
    "        print(\"Waiting for Endpoint to Update\")\n",
    "        time.sleep(15)\n",
    "        response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response.get(\"EndpointStatus\")\n",
    "\n",
    "    if status != \"InService\":\n",
    "        print(f\"Failed to update endpoint, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to update endpoint {endpoint_response['EndpointArn']}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Endpoint {endpoint_response['EndpointArn']} successfully updated.\")\n",
    "\n",
    "wait_for_endpoint_update_complete(endpoint=endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "When the cell completes, an endpoint ARN is returned that looks like *arn:aws:sagemaker:us-west-2:012345678910:endpoint/abalone-2040-10-11-10-11-12*.\n",
    "\n",
    "Your endpoint is currently configured with one variant, the production model. You can view the endpoint configuration using *describe_endpoint*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#describe-the-endpoint\n",
    "sm.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3: Generate a baseline for model quality performance\n",
    "\n",
    "In this task, you invoke the endpoint created above using validation data. Predictions from the deployed model using this validation data is used as a baseline dataset. You then use SageMaker’s Model Monitoring to execute a baseline job that computes model performance data, and suggest model quality constraints based on the baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#invoke-the-endpoint\n",
    "cutoff = 0.8\n",
    "# Create the SageMaker Predictor object\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                        serializer=CSVSerializer(),\n",
    "                        deserializer=CSVDeserializer())\n",
    "\n",
    "validate_dataset = \"validation_with_predictions.csv\"\n",
    "\n",
    "limit = 200  # Need at least 200 samples to compute standard deviations\n",
    "i = 0\n",
    "with open(f\"data/{validate_dataset}\", \"w\") as validation_file:\n",
    "    validation_file.write(\"probability,prediction,label\\n\")  # CSV header\n",
    "    with open(\"data/abalone_data_new.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            probability = float(predictor.predict(input_cols)[0][0])\n",
    "            prediction = \"1\" if probability > cutoff else \"0\"\n",
    "            validation_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            sleep(0.1)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#configure-baseline-variables\n",
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_dataset_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the predictions as a baseline dataset.\n",
    "\n",
    "Now, you upload the predictions made using validation dataset to S3 which are used for creating model quality baseline statistics and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upload-predictions-to-s3\n",
    "baseline_dataset_uri = S3Uploader.upload(f\"data/{validate_dataset}\", baseline_data_uri)\n",
    "baseline_dataset_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.4: Create a baselining job with validation dataset predictions\n",
    "\n",
    "Now, you define the model quality monitoring object and execute the model quality monitoring baseline job. Model monitor automatically generates baseline statistics and constraints based on the validation dataset provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-model-quality-monitoring-object\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sm_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\" aria-hidden=\"true\"></i> **Note:** The baselining job can take 7-8 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suggest-baseline\n",
    "baseline_job_name = f\"model-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "# specify the problem type, in this case regression, and provide other required attributes.\n",
    "job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=\"data/validation_with_predictions.csv\", \n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = baseline_results_uri,  # the S3 location to store the results.\n",
    "    problem_type=\"Regression\",\n",
    "    inference_attribute= \"prediction\",  # the column in the dataset that contains predictions.\n",
    "    probability_attribute= \"probability\",  # the column in the dataset that contains probabilities.\n",
    "    ground_truth_attribute= \"label\"  # the column in the dataset that contains ground truth labels.\n",
    ")\n",
    "job.wait(logs=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fas fa-sticky-note\" style=\"color:#ec7211\"></i> **NOTE:** This code returns a lengthy response. You can ignore any warnings or error messages.\n",
    "\n",
    "When the cell completes, a message is returned that looks like *2025-10-11 12:13:14,156 - DefaultDataAnalyzer - INFO - Spark job completed*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.5: Explore the results of the baselining job\n",
    "\n",
    "In this task, you explore the results of the baselining job.\n",
    "\n",
    "The baseline constraints and statistics files are uploaded to the S3 location.\n",
    "\n",
    "List details from the baseline statistics and constraints files from the latest baselining job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-statistics\n",
    "baseline_job = model_quality_monitor.latest_baselining_job\n",
    "binary_metrics = baseline_job.baseline_statistics().body_dict[\"regression_metrics\"]\n",
    "pd.json_normalize(binary_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#view-constraints\n",
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"regression_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that you have a baseline created and have viewed the statistics and constraints, create a Model Monitor model quality monitoring job to track new inference records against the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.6: Create model monitoring to identify model quality drift\n",
    "\n",
    "In addition to the generated baseline, model quality monitoring needs two additional inputs - predictions made by the deployed model endpoint and the ground truth data to be provided by the model consuming application. Since you already enabled data capture on the endpoint, prediction data is captured in S3.\n",
    "\n",
    "The ground truth data depends on the what your model is predicting and what the business use case is. In this case, since the model is predicting abalone rings, ground truth data indicates the number of rings of an abalone. For the purposes of this notebook, you generate synthetic data as ground truth.\n",
    "\n",
    "In this task, you send some artificial traffic. If there is no traffic, the monitoring jobs are marked as *Failed* since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#send-artificial-traffic\n",
    "endpoint_name = predictor.endpoint_name\n",
    "runtime_client = sm_session.sagemaker_runtime_client\n",
    "limit = 200\n",
    "i = 0\n",
    "\n",
    "# repeating code from above to run this section independently\n",
    "def invoke_endpoint(ep_name, file_name, runtime_client):\n",
    "    i = 0\n",
    "    with open(file_name, \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, payload) = row.strip(\"\\n\").split(\",\", 1)  \n",
    "\n",
    "            response = runtime_client.invoke_endpoint(\n",
    "                EndpointName=ep_name, ContentType=\"text/csv\", Body=payload, InferenceId=str(i),\n",
    "            )\n",
    "            response[\"Body\"].read()\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(0.1)\n",
    "\n",
    "\n",
    "invoke_endpoint(endpoint_name, \"data/abalone_data_skewed.csv\", runtime_client)\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the new attribute *InferenceId*, which you are setting when invoking the endpoint. This is used to join the prediction data with the ground truth data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.7: View captured data\n",
    "\n",
    "In this task, you list and view the data capture files stored in Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#view-captured-data\n",
    "print(\"Waiting for captures to show up \\n\", end=\"\")\n",
    "capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "if capture_files:\n",
    "    capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "    capture_record = json.loads(capture_file[0])\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, view the contents of a single capture file. Here you should see all the data captured in an Amazon SageMaker specific JSON-line formatted file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(capture_file[-3:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the contents of a single line is present below in a formatted JSON file so that you can observe a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(capture_record, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, notice the *InferenceId* attribute that is set as part of the *invoke_endpoint* call. If this is present, can be joined with ground truth data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.8: Generate synthetic ground truth\n",
    "\n",
    "In this task, you generate ground truth data. The model quality job fails if there is no ground truth data to merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of building and maintaining a more accurate model you sometimes need a combination of ground truth data + synthetic data. This synthetic (fake) data can be created from a baselining job and constraints that closely mimic real ground truth. \n",
    "\n",
    "Synthetic data can be a good solution when ground truth data is not enough. Another situation where synthetic data can help is when there are privacy concerns. \n",
    "\n",
    "In this task, since our model has not been in production for long time, we have not captured and labeled ground truth data, so we are using synthetic data for our Model Monitoring job.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate-ground-truth\n",
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    rand = random.randrange(20)\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": rand,\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(records, upload_time):\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upload-ground-truth-data\n",
    "def generate_fake_ground_truth():\n",
    "    j = 0\n",
    "    while True:\n",
    "        fake_records = [ground_truth_with_id(i) for i in range(200)]\n",
    "        upload_ground_truth(fake_records, datetime.utcnow())\n",
    "        j = (j + 1) % 5\n",
    "        sleep(60 * 60)  # do this once an hour\n",
    "\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth)\n",
    "gt_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.9: Create a monitoring schedule\n",
    "\n",
    "In this task, you create a monitoring schedule to run a model quality monitoring job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-monitoring-schedule-name\n",
    "monitor_schedule_name = (\n",
    "    f\"monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-endpoint-input\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    probability_attribute=\"0\",\n",
    "    probability_threshold_attribute=0.5,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    "    inference_attribute = \"0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-monitoring-schedule\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "response = model_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=monitor_schedule_name,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type=\"Regression\",\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#describe-monitoring-schedule\n",
    "model_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.10: Examine monitoring schedule executions\n",
    "\n",
    "The monitor schedule starts jobs at the previously specified hourly interval. Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule your execution. You might see your execution start anywhere from 0 to 20 minutes from the hour boundary. This is expected and done for load balancing in the backend.\n",
    "\n",
    "This execution takes approximately one hour to be able to generate the violations report. For the purpose of the lab, the next cells have code snippets for you to view and sample output is shared for reference. In the last step of this task, you view the violations report from a file that was generated and pre-loaded from an earlier monitoring run.\n",
    "\n",
    "In this task, you list the executions of the monitoring schedules and review the status of each of the executions.\n",
    "\n",
    "- With the hourly schedule that was configured in the previous step, the monitor looks for new data capture files in S3 for the previous hour.\n",
    "- If no files are found, then the status of that execution is reported as 'Failed'. This can happen if no traffic was sent to the endpoint in the previous hour.\n",
    "- If the execution status is reported as 'CompletedWithViolations', you should see the corresponding violations file in S3 in the path specified in previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to list and view the current status of an execution, you can use code similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# List monitoring schedules for endpoint\n",
    "print('Monitoring schedules for endpoint \\'{}\\':\\n'.format(endpoint_name))\n",
    "print(sm.list_monitoring_schedules(EndpointName=endpoint_name))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# Model Quality Monitor - monitoring executions\n",
    "print('Monitoring executions for schedule \\'{}\\':\\n'.format(monitor_schedule_name))\n",
    "print(sm.list_monitoring_executions(MonitoringScheduleName=monitor_schedule_name,\n",
    "                                           EndpointName=predictor.endpoint_name,\n",
    "                                           MonitoringTypeEquals='ModelQuality',\n",
    "                                           SortBy='CreationTime',\n",
    "                                           SortOrder='Descending'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# Wait for the first execution of the monitoring_schedule\n",
    "print(\"Waiting for first execution\", end=\"\")\n",
    "while True:\n",
    "    execution = model_quality_monitor.describe_schedule().get(\n",
    "        \"LastMonitoringExecutionSummary\"\n",
    "    )\n",
    "    if execution:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(10)\n",
    "print()\n",
    "print(\"Execution found!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Get the status of the Monitoring job and the execution summary with or without violations\n",
    "status = execution[\"MonitoringExecutionStatus\"]\n",
    "\n",
    "while status in [\"Pending\", \"InProgress\"]:\n",
    "    print(\"Waiting for execution to finish\", end=\"\")\n",
    "    latest_execution.wait(logs=False)\n",
    "    latest_job = latest_execution.describe()\n",
    "    print()\n",
    "    print(f\"{latest_job['ProcessingJobName']} job status:\", latest_job[\"ProcessingJobStatus\"])\n",
    "    print(\n",
    "        f\"{latest_job['ProcessingJobName']} job exit message, if any:\",\n",
    "        latest_job.get(\"ExitMessage\"),\n",
    "    )\n",
    "    print(\n",
    "        f\"{latest_job['ProcessingJobName']} job failure reason, if any:\",\n",
    "        latest_job.get(\"FailureReason\"),\n",
    "    )\n",
    "    sleep(\n",
    "        30\n",
    "    )  # model quality executions consist of two Processing jobs, wait for second job to start\n",
    "    latest_execution = model_quality_monitor.list_executions()[-1]\n",
    "    execution = model_quality_monitor.describe_schedule()[\"LastMonitoringExecutionSummary\"]\n",
    "    status = execution[\"MonitoringExecutionStatus\"]\n",
    "\n",
    "print(\"Execution status is:\", status)\n",
    "\n",
    "if status != \"Completed\":\n",
    "    print(execution)\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# Get the violations report S3uri\n",
    "latest_execution = model_quality_monitor.list_executions()[-1]\n",
    "report_uri = latest_execution.describe()[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "    \"S3Uri\"\n",
    "]\n",
    "print(\"Report Uri:\", report_uri)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the generated violation report, you can use code similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# View violations generated by monitoring schedule\n",
    "pd.options.display.max_colwidth = None\n",
    "violations = latest_execution.constraint_violations().body_dict[\"violations\"]\n",
    "violations_df = pd.json_normalize(violations)\n",
    "violations_df.head(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the execution of the monitoring job you started above does not finish for 60-80 minutes, view a violations report from a file that was generated and pre-loaded from an earlier monitoring run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-violations-report\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "violations = json.load(open('data/constraint_violations.json'))\n",
    "constraints_df=pd.json_normalize(violations, record_path=['violations'])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.11: Analyze model quality CloudWatch metrics\n",
    "\n",
    "In addition to the violations, the monitoring schedule also emits CloudWatch metrics.\n",
    "\n",
    "You use the built-in Amazon SageMaker Model Monitor container for CloudWatch metrics. SageMaker emits the metrics for each feature observed in the dataset in the */aws/sagemaker/Endpoints/model-metric* namespace with *EndpointName* and *ScheduleName* dimensions\n",
    "\n",
    "In this task, you view the metrics generated and set up an CloudWatch alarm to be triggered when the model quality drifts from the baseline thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-CloudWatch-client\n",
    "cw_client = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "\n",
    "cw_dimensions = [\n",
    "    {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "    {\"Name\": \"MonitoringSchedule\", \"Value\": monitor_schedule_name},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you create an alarm if the r2 value of the model fall below the threshold suggested by the baseline constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-CloudWatch-alarm\n",
    "previous_date = f'{datetime.today() - timedelta(days=1):%Y-%m-%d}'\n",
    "print (previous_date)\n",
    "alarm_name = \"MODEL_QUALITY_R2_SCORE\"\n",
    "alarm_desc = (\n",
    "    \"Trigger an CloudWatch alarm when the r2 score drifts away from the baseline constraints\"\n",
    ")\n",
    "model_quality_r2_drift_threshold = (\n",
    "    0.625  ##Setting this threshold purposefully low to see the alarm quickly.\n",
    ")\n",
    "metric_name = \"r2\"\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "endpoint_name = 'Abalone-' + previous_date\n",
    "print (endpoint_name)\n",
    "monitoring_schedule_name = 'model-monitor-schedule-' + previous_date\n",
    "\n",
    "cw_client.put_metric_alarm(\n",
    "    AlarmName=alarm_name,\n",
    "    AlarmDescription=alarm_desc,\n",
    "    ActionsEnabled=True,\n",
    "    MetricName=metric_name,\n",
    "    Namespace=namespace,\n",
    "    Statistic=\"Average\",\n",
    "    Dimensions=[\n",
    "        {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "        {\"Name\": \"MonitoringSchedule\", \"Value\": monitor_schedule_name},\n",
    "    ],\n",
    "    Period=600,\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=model_quality_r2_drift_threshold,\n",
    "    ComparisonOperator=\"LessThanOrEqualToThreshold\",\n",
    "    TreatMissingData=\"breaching\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You created a CloudWatch alarm. You can use this alarm to notify you of any model drift issues and trigger automatic model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup\n",
    "model_quality_monitor.delete_monitoring_schedule()\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
