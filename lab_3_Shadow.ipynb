{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Shadow testing\n",
    "\n",
    "In this notebook, you implement a shadow testing strategy by configuring and testing production and shadow model variants. You review results from the production and shadow model variants, and identify the model with the best performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Environment setup\n",
    "\n",
    "Install the required libraries and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.session import production_variant\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "s3 = boto3.Session().client(\"s3\")\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'sagemaker/abalone'\n",
    "data_capture_prefix = 'sagemaker/abalone/models'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Create an endpoint\n",
    "\n",
    "You already used A/B testing to send traffic to the new model. AnyCompany is interested in using either A/B testing or Shadow testing, depending on which one works the best with their business requirements. Before committing to a deployment strategy, try another model testing and deployment strategy.\n",
    "\n",
    "You use shadow testing to send traffic to the new model without disrupting the traffic that is sent to the production endpoint. Shadow testing helps minimize the risk of deploying a low-performing model into production. It also gives a more realistic comparison between the two models by using the same data for inference and minimizes downtime. \n",
    "\n",
    "To start, upload the new model to an Amazon Simple Storage Service (Amazon S3) bucket with the current model that is in production. Next, create the production endpoint. Finally, update the endpoint to add the new model as a shadow variant.\n",
    "\n",
    "First, upload the models to the S3 bucket. The current model in production is *model_A.tar.gz* and the new model is *model_B.tar.gz*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upload-models\n",
    "model_url = S3Uploader.upload(\n",
    "    local_path=\"models/model_A.tar.gz\", desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "model_url2 = S3Uploader.upload(\n",
    "    local_path=\"models/model_B.tar.gz\", desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "model_url, model_url2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create model definitions for the pre-trained abalone models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-model-definitions\n",
    "model_name = f\"abalone-A-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "model_name2 = f\"abalone-B-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "image_uri = retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "image_uri2 = retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "\n",
    "response = sm_session.create_model(\n",
    "    name=model_name, role=role, container_defs={\"Image\": image_uri, \"ModelDataUrl\": model_url}\n",
    ")\n",
    "\n",
    "response_2 = sm_session.create_model(\n",
    "    name=model_name2, role=role, container_defs={\"Image\": image_uri2, \"ModelDataUrl\": model_url2}\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the production endpoint configuration. When you create an endpoint with *create_endpoint*, you must include an **EndpointName** and an **EndpointConfigName**. \n",
    "\n",
    "The endpoint configuration for shadow testing is defined the same way that a production variant is defined. When you use *create_endpoint*, you can use **ProductionVariants** and **ShadowVariants** to distinguish between the current production model and the new shadow model. Model A, the model currently in production, is set up as a *ProductionVariant*. Model B, the model from the prior lab that you want to deploy in shadow mode, is set up as a *ShadowVariant* later in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-endpoint-configuration\n",
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = 'Abalone-Shadow-Testing-Endpoint',\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'ModelName':model_name,\n",
    "            'InstanceType':'ml.m5.xlarge',\n",
    "            'InitialInstanceCount':2,\n",
    "            'VariantName':'Production-Model-A',\n",
    "            'InitialVariantWeight':1\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create an endpoint with the endpoint configuration.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** The endpoint creation takes approximately 4â€“5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-endpoint\n",
    "endpoint_name = f\"Abalone-Shadow-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "endpoint_params = {'EndpointName': endpoint_name, 'EndpointConfigName': 'Abalone-Shadow-Testing-Endpoint'}\n",
    "\n",
    "endpoint_response = sm.create_endpoint(EndpointName=endpoint_name, EndpointConfigName='Abalone-Shadow-Testing-Endpoint')\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))\n",
    "\n",
    "def wait_for_endpoint_creation_complete(endpoint):\n",
    "    \"\"\"Helper function to wait for the completion of creating an endpoint\"\"\"\n",
    "    response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response.get(\"EndpointStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Endpoint Creation\")\n",
    "        time.sleep(15)\n",
    "        response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response.get(\"EndpointStatus\")\n",
    "\n",
    "    if status != \"InService\":\n",
    "        print(f\"Failed to create endpoint, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create endpoint {endpoint_response['EndpointArn']}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Endpoint {endpoint_response['EndpointArn']} successfully created.\")\n",
    "\n",
    "wait_for_endpoint_creation_complete(endpoint=endpoint_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your production endpoint is ready to use. Send test traffic to the endpoint by using *invoke_endpoint*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#send-test-data\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "with open(\"data/abalone_data_test.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        sm_runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload)\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a shadow model to an endpoint in production requires two steps. First, you create a new endpoint configuration that includes a shadow production variant. Then, you update the endpoint to use the new endpoint configuration. If any issues arise, you can roll back a shadow model by updating the endpoint configuration.\n",
    "\n",
    "Log the requests and responses of both production and shadow variants by using Data Capture. The Data Capture logs are stored in an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-endpoint-configuration\n",
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = 'Abalone-Shadow-Testing-Endpoint-2',\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            'ModelName':model_name,\n",
    "            'InstanceType':'ml.m5.xlarge',\n",
    "            'InitialInstanceCount':2,\n",
    "            'VariantName':'Production-Model-A',\n",
    "            'InitialVariantWeight':1\n",
    "        }\n",
    "    ],\n",
    "    ShadowProductionVariants = [\n",
    "        {\n",
    "            'ModelName': model_name2,\n",
    "            'InstanceType': 'ml.m5.xlarge',\n",
    "            'InitialInstanceCount':2,\n",
    "            'VariantName':'New-Model-B',\n",
    "            'InitialVariantWeight':1,\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        'EnableCapture': True,\n",
    "        'InitialSamplingPercentage': 100,\n",
    "        'DestinationS3Uri': \"s3://{}/{}\".format(bucket, data_capture_prefix),\n",
    "        'CaptureOptions': [{'CaptureMode': 'Input'}, {'CaptureMode': 'Output'}],\n",
    "        'CaptureContentTypeHeader': {'CsvContentTypes': ['text/csv']}\n",
    "    }\n",
    ")\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the endpoint with your new endpoint configuration. Then, wait until the endpoint is in service again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#update-endpoint\n",
    "endpoint_params = {'EndpointName': endpoint_name, 'EndpointConfigName': 'Abalone-Shadow-Testing-Endpoint-2'}\n",
    "\n",
    "endpoint_response = sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName='Abalone-Shadow-Testing-Endpoint-2')\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))\n",
    "\n",
    "def wait_for_endpoint_update_complete(endpoint):\n",
    "    \"\"\"Helper function to wait for the completion of updating an endpoint\"\"\"\n",
    "    response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response.get(\"EndpointStatus\")\n",
    "    while status == \"Updating\":\n",
    "        print(\"Waiting for Endpoint to Update\")\n",
    "        time.sleep(15)\n",
    "        response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response.get(\"EndpointStatus\")\n",
    "\n",
    "    if status != \"InService\":\n",
    "        print(f\"Failed to update endpoint, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to update endpoint {endpoint_response['EndpointArn']}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Endpoint {endpoint_response['EndpointArn']} successfully updated.\")\n",
    "\n",
    "wait_for_endpoint_update_complete(endpoint=endpoint_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cell completes, an endpoint Amazon Resource Name (ARN) is returned that looks like *'arn:aws:sagemaker:us-west-2:012345678910:endpoint/abalone-shadow-2025-01-01-01-01-00'*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3: Evaluate invocation metrics\n",
    "\n",
    "To test the endpoint, invoke the deployed models and evaluate the invocation metrics. You can send data to the endpoint that you created in the prior task to get inferences in real time. The data science team received a new set of data and sent it to you. Test the models by using this new data.\n",
    "\n",
    "First, get a subset of the test data for a sample of the invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import-data\n",
    "shape=pd.read_csv(\"data/abalone_data_test.csv\", header=0)\n",
    "shape.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, send traffic to the endpoint by using **invoke_endpoint**.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** The endpoint invocation takes approximately 1â€“2 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#send-test-data\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "with open(\"data/abalone_data_test.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        sm_runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload)\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker emits metrics such as latency and invocations for each variant in Amazon CloudWatch. To show how invocations are split across variants, query the number of invocations per variant from CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get-cloudwatch-metrics\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_name, start_time, end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "    )\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop(\"Unit\", axis=1)\n",
    "        .rename(columns={\"Sum\": variant_name})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics(start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "    end_time = datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, 'Production-Model-A', start_time, end_time\n",
    "    )\n",
    "    metrics_variant2 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, 'New-Model-B', start_time, end_time\n",
    "    )\n",
    "    metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants\n",
    "\n",
    "print(\"Waiting a minute for initial metric creation...\")\n",
    "time.sleep(120)  # The metrics and data capture need time to log and save all of the files\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table, you see the number of invocations for Model A, the production model. You also see the number of invocations for Model B, the new model. \n",
    "\n",
    "In the chart, you see the number of invocations per model variant over a period of time. \n",
    "\n",
    "You can see that the traffic starts out only on Model A. This behavior occurs because you sent traffic to the endpoint when the only model variant was the production model. Then, after the shadow model was added, you can see that the traffic is equivalent for both models. The lines overlap each other at every point. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3.4: Evaluate the models with production data\n",
    "\n",
    "All of the endpoint input and output data is captured with Data Capture. You can access the Data Capture logs and view each event by getting the log objects from the S3 bucket. When accessing the data, notice that the input is encoded as *CSV*. The data that is sent to the endpoint is included in *endpointInput*. The prediction is included in *endpointOutput*. Each inference event has a unique *eventId*, so you are able to match the production and shadow invocations based on their *eventId*. \n",
    "\n",
    "To evaluate the models, use the logs that are stored in the S3 bucket. With these logs, you can see the predictions that the production and shadow models generated from the single production endpoint.\n",
    "\n",
    "First, view a log file from the data that was captured from the production variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#view-production-variant-data\n",
    "current_endpoint_capture_prefix = \"{}/{}/{}\".format(data_capture_prefix, endpoint_name, 'Production-Model-A')\n",
    "result = s3.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "prod_var_capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "\n",
    "def get_obj_body(obj_key):\n",
    "    return s3.get_object(Bucket=bucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\n",
    "\n",
    "prod_var_capture_file = get_obj_body(prod_var_capture_files[-1])\n",
    "print(json.dumps(json.loads(prod_var_capture_file.split('\\n')[0]), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, convert the production variant captured data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert-production-data-to-pandas-dataframe\n",
    "prod_input_list = []\n",
    "for i in range(len(prod_var_capture_files)):\n",
    "    prod_var_capture_file = get_obj_body(prod_var_capture_files[i])\n",
    "    for i in range(len(prod_var_capture_file.split('\\n'))):\n",
    "        if not len(prod_var_capture_file.split('\\n')[i]) == 0:\n",
    "            prod_input = {}\n",
    "            prod_input[\"input\"] = json.loads(prod_var_capture_file.split('\\n')[i])[\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "            data = json.loads(json.loads(prod_var_capture_file.split('\\n')[i])[\"captureData\"][\"endpointOutput\"][\"data\"])\n",
    "            prod_input[\"prod_output\"] = data\n",
    "            prod_input[\"eventId\"] = json.loads(prod_var_capture_file.split('\\n')[i])[\"eventMetadata\"][\"eventId\"]\n",
    "            prod_input_list.append(prod_input)\n",
    "\n",
    "from pandas import json_normalize\n",
    "prod_var_df = json_normalize(prod_input_list)\n",
    "prod_var_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, view a log file from the data that was captured from the shadow variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#view-shadow-variant-data\n",
    "current_endpoint_capture_prefix = \"{}/{}/{}\".format(data_capture_prefix, endpoint_name, 'New-Model-B')\n",
    "result = s3.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "shadow_var_capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "\n",
    "def get_obj_body(obj_key):\n",
    "    return s3.get_object(Bucket=bucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\n",
    "\n",
    "shadow_var_capture_file = get_obj_body(shadow_var_capture_files[-1])\n",
    "print(json.dumps(json.loads(shadow_var_capture_file.split('\\n')[0]), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, convert the shadow variant captured data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert-shadow-data-to-pandas-dataframe\n",
    "shadow_input_list = []\n",
    "for i in range(len(shadow_var_capture_files)):\n",
    "    shadow_var_capture_file = get_obj_body(shadow_var_capture_files[i])\n",
    "    for i in range(len(shadow_var_capture_file.split('\\n'))):\n",
    "        if not len(shadow_var_capture_file.split('\\n')[i]) == 0:\n",
    "            shadow_input = {}\n",
    "            shadow_input[\"input\"] = json.loads(shadow_var_capture_file.split('\\n')[i])[\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "            data = json.loads(json.loads(shadow_var_capture_file.split('\\n')[i])[\"captureData\"][\"endpointOutput\"][\"data\"])\n",
    "            shadow_input[\"shadow_output\"] = data\n",
    "            shadow_input[\"eventId\"] = json.loads(shadow_var_capture_file.split('\\n')[i])[\"eventMetadata\"][\"eventId\"]\n",
    "            shadow_input_list.append(shadow_input)\n",
    "\n",
    "shadow_var_df = json_normalize(shadow_input_list)\n",
    "shadow_var_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Capture helps keep track of many model variants and their inference results during deployment. You can use the data that you just collected to see how the models compare.\n",
    "\n",
    "Compare the predicted abalone ring values from the production and shadow variants. Append the ring labels from the original dataset to see the difference between the actual number of rings and the production output, and the actual number of rings and the shadow output.\n",
    "\n",
    "When you are finished, the table includes:\n",
    "- Headings for *eventId*\n",
    "- The original *input*\n",
    "- The production model output as *prod_output*\n",
    "- The shadow model output as *shadow_output*\n",
    "- The original *labels* that tell the actual age of the abalone\n",
    "- The difference between the prod_output and the label as *prod_diff*\n",
    "- The difference between the shadow_output and the label as *shadow_diff*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compile-data-capture-with-labels\n",
    "df_with_labels = pd.read_csv(\"data/abalone_data_new.csv\", header=None)\n",
    "test_labels = df_with_labels.iloc[:, 0]\n",
    "\n",
    "final_df = pd.merge(prod_var_df, shadow_var_df, on='eventId', how='right')\n",
    "final_df['labels'] =  test_labels\n",
    "final_df = final_df.drop('input_y', axis=1)\n",
    "final_df = final_df.assign(prod_diff=final_df['prod_output'] - final_df['labels'])\n",
    "final_df = final_df.assign(shadow_diff=final_df['shadow_output'] - final_df['labels'])\n",
    "final_df = final_df[['eventId','input_x','prod_output','shadow_output','labels','prod_diff','shadow_diff']]\n",
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review each prediction's variance and see how far each prediction is from the actual values. During the shadow deployment, each inference request was sent to both models. Thus, the results include 2000 predictions from the production model and 2000 predictions from the shadow model. The most straightforward way to evaluate the predictions is as follows: Find the absolute value of the difference between the prediction and the actual value, and then average these differences.\n",
    "\n",
    "For instance, if the abalone has 11 rings, but the production prediction is 9.3, the difference between these values is -1.7. The absolute value of -1.7 is 1.7. Find the absolute value for every difference, add them up, and divide the total by the number of inferences. In this way, you can find the average difference of the absolute values. A lower average difference means that the model predictions are generally more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate-average-absolute-difference\n",
    "prod_diff_average = final_df.loc[:, 'prod_diff'].abs().mean()\n",
    "shadow_diff_average = final_df.loc[:, 'shadow_diff'].abs().mean()\n",
    "\n",
    "print(\"These are the averages of the absolute value of the difference between each model's inference results and the actual values (lower scores are more accurate):\")\n",
    "print(\"Production model variant: {}\".format(prod_diff_average))\n",
    "print(\"Shadow model variant: {}\".format(shadow_diff_average))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the shadow model has a higher average difference than the production model variant. This result indicates that the shadow model is likely not as good at predicting the actual number of rings as the current production model.\n",
    "\n",
    "You can see the results in more detail by creating charts of the data you collected from the Data Capture logs. Graph the average difference of the number of rings for the production and shadow models. This graph shows you, for each number of rings, how close each model is to predicting the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graph-model-differences-from-labels\n",
    "final_df['prod_diff'] = final_df['prod_diff'].abs()\n",
    "final_df['shadow_diff'] = final_df['shadow_diff'].abs()\n",
    "grouped_df = final_df.groupby(['labels']).agg(prod_diff_average=('prod_diff', 'mean'), shadow_diff_average=('shadow_diff' , 'mean'))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df = grouped_df.melt(id_vars=['labels'], value_vars=['prod_diff_average', 'shadow_diff_average'])\n",
    "\n",
    "sb.barplot(x=grouped_df.labels,\n",
    "           y=grouped_df.value,\n",
    "           hue=grouped_df.variable,\n",
    "           data=grouped_df).set(title='Difference in Prediction Scores by Number of Rings', xlabel='Number of Rings', ylabel='Absolute Difference in Predicted to Actual Rings')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows that the production and shadow models have similar variances for each ring value. The production model has lower variance for some of the ring values, and the shadow model has lower variance for other ring values.\n",
    "\n",
    "You have collected a list of predicted values. Now, you can evaluate the R-squared score (R2 score), mean absolute error (MAE), and root mean squared error (RMSE) metrics for each variant. These metrics help determine whether the new model is an improvement over the one currently in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate-model-metrics\n",
    "labels = final_df['labels']\n",
    "prod_preds = final_df['prod_output']\n",
    "shadow_preds = final_df['shadow_output']\n",
    "\n",
    "# Calculate R2\n",
    "prod_score = r2_score(labels, prod_preds)\n",
    "shadow_score = r2_score(labels, shadow_preds)\n",
    "print(\"The R2 score of the production model is {}\".format(round(prod_score, 2)))\n",
    "print(\"The R2 score of the shadow model is {}\\n\".format(round(shadow_score, 2)))\n",
    "\n",
    "# Calculate MAE\n",
    "prod_score = mean_absolute_error(labels, prod_preds)\n",
    "shadow_score = mean_absolute_error(labels, shadow_preds)\n",
    "print(\"The Mean Absolute Error of the production model is {}\".format(round(prod_score, 2)))\n",
    "print(\"The Mean Absolute Error of the shadow model is {}\\n\".format(round(shadow_score, 2)))\n",
    "\n",
    "# Calculate RMSE\n",
    "prod_score = np.sqrt(mean_absolute_error(labels, prod_preds))\n",
    "shadow_score = np.sqrt(mean_absolute_error(labels, shadow_preds))\n",
    "print(\"The Root Mean Squared Error of the production model is {}\".format(round(prod_score, 2)))\n",
    "print(\"The Root Mean Squared Error of the shadow model is {}\\n\".format(round(shadow_score, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shadow model is not performing as well as the current production model. The R2 score is lower, the MAE is higher, and the RMSE is higher. With a lower R2 score, you are confident that the shadow model is not improvement over the current production model. The team is going back to testing and tuning the model so they can try to improve on these results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully implemented a shadow testing strategy by configuring and testing production and shadow model variants. You reviewed results from the production and shadow model variants, and identified the model with the best performance.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
