{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: A/B testing\n",
    "\n",
    "In this notebook, you configure an A/B testing strategy, test model variants, and review the performance of the model variants."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Environment setup\n",
    "\n",
    "Install the required libraries and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.session import production_variant\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'sagemaker/abalone'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Create an endpoint\n",
    "\n",
    "Your company just finished creating a new model they want to test. In this lab, you upload the new model to an Amazon Simple Storage Service (Amazon S3) bucket with the current model that is in production. Then, you create model variants. Finally, you create an endpoint with the production variants.\n",
    "\n",
    "First, upload the models to the Amazon S3 bucket. The current model in production is *model_A.tar.gz*, and the new model is *model_B.tar.gz*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upload-models\n",
    "model_url = S3Uploader.upload(\n",
    "    local_path=\"models/model_A.tar.gz\", desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "model_url2 = S3Uploader.upload(\n",
    "    local_path=\"models/model_B.tar.gz\", desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "model_url, model_url2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create model definitions for the pre-trained abalone models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-model-definitions\n",
    "model_name = f\"abalone-A-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "model_name2 = f\"abalone-B-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "image_uri = retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "image_uri2 = retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "\n",
    "response = sm_session.create_model(\n",
    "    name=model_name, role=role, container_defs={\"Image\": image_uri, \"ModelDataUrl\": model_url}\n",
    ")\n",
    "\n",
    "response_2 = sm_session.create_model(\n",
    "    name=model_name2, role=role, container_defs={\"Image\": image_uri2, \"ModelDataUrl\": model_url2}\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create two variants, each with its own model. Set *initial_weight* to 1 for both variants so 50 percent of the requests go to **Production-Model-A** and 50 percent of the requests go to **New-Model-B**.\n",
    "\n",
    "To create a production variant, you must configure the following options:\n",
    "- **model_name**: The name of the model that you want to host. You specified this name when you created the model.\n",
    "- **instance_type**: The compute instance type.\n",
    "- **initial_instance_count**: The number of instances to launch initially.\n",
    "- **variant_name**: The name of the production variant (one or more models in production).\n",
    "- **initial_weight**: The starting weight for each variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-production-variants\n",
    "variant1 = production_variant(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    initial_instance_count=4,\n",
    "    variant_name=\"Production-Model-A\",\n",
    "    initial_weight=1,\n",
    ")\n",
    "variant2 = production_variant(\n",
    "    model_name=model_name2,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    initial_instance_count=4,\n",
    "    variant_name=\"New-Model-B\",\n",
    "    initial_weight=1,\n",
    ")\n",
    "\n",
    "(variant1, variant2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create an endpoint with the two variants.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** The endpoint creation takes approximately 4–5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create-endpoint\n",
    "endpoint_name = f\"Abalone-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "sm_session.endpoint_from_production_variants(\n",
    "    name=endpoint_name, production_variants=[variant1, variant2]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cell completes, an endpoint name is returned that looks like *Abalone-2025-01-01-01-01-00*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Evaluate invocation metrics\n",
    "\n",
    "Amazon SageMaker emits metrics such as latency and invocations for each variant in Amazon CloudWatch. To test the endpoint, invoke the deployed models and evaluate the invocation metrics. You can send data to the endpoint that you created in the prior task to get inferences in real time. The data science team received a new set of data and sent it to you. Test the models by using this new data.\n",
    "\n",
    "First, get a subset of the test data for a sample of the invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import-data\n",
    "shape=pd.read_csv(\"data/abalone_data_test.csv\", header=0)\n",
    "shape.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, send traffic to the endpoint by using **invoke_endpoint**.\n",
    "\n",
    "<i class=\"fas fa-sticky-note\" style=\"color:#ff6633\"></i> **Note:** The endpoint invocation takes approximately 1–2 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#send-test-data\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "with open(\"data/abalone_data_test.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        sm_runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload)\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how invocations are split across variants, query the number of invocations per variant from CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get-cloudwatch-metrics\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_name, start_time, end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "    )\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop(\"Unit\", axis=1)\n",
    "        .rename(columns={\"Sum\": variant_name})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics(start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "    end_time = datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variant1[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variant2 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variant2[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants\n",
    "\n",
    "print(\"Waiting a minute for initial metric creation...\")\n",
    "time.sleep(60)\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table reports the number of invocations for Model A, the production model. It also reports the number of invocations for Model B, the new model. The chart plots the number of invocations per model variant over a period of time. The table and chart indicate that traffic is distributed evenly between the two variants.\n",
    "\n",
    "When you are conducting A/B testing, you can invoke a specific variant by specifying the *TargetVariant* when calling *invoke_endpoint*. Invoke the variant that is currently in production, **Production-Model-A**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get-model-A-predictions\n",
    "predictions = \"\"\n",
    "\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "with open(\"data/abalone_data_test.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"text/csv\",\n",
    "            Body=payload,\n",
    "            TargetVariant=variant1[\"VariantName\"],\n",
    "        )\n",
    "        predictions = \",\".join([predictions, response[\"Body\"].read().decode(\"utf-8\")])\n",
    "f.close()\n",
    "\n",
    "# Convert the predictions to a numpy array and round the values\n",
    "pred_np = np.fromstring(predictions[1:], sep=\",\")\n",
    "preds = np.round(pred_np)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the traffic per variant again. This time, you see that the number of invocations only incremented for *Production-Model-A* because all of the invocations were targeted at that variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot-model-A-metrics\n",
    "time.sleep(20)  # let metrics catch up\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2.4: Evaluate the models with production data\n",
    "\n",
    "To see if the new model is an improvement over the one currently in production, evaluate both models and compare their results. Using a list of predicted values, you can evaluate the R-Squared Score (R2 score), mean absolute error (MAE), and root mean square error (RMSE) metrics for each variant. These metrics help to determine whether the new model is an improvement over the one currently in production.\n",
    "\n",
    "Metric definitions:\n",
    "- **R2 score:** The R2 score compares the fit of the chosen model with that of a horizontal straight line (the null hypothesis). The R2 score can range from -1 to 1. A negative R2 score means the model is a poor fit for the data. A higher positive score indicates a better fit.\n",
    "- **MAE:** The difference between the actual and predicted values, divided by the total number of points in the dataset. It helps you to determine how close the predictions are to the actual model on average.\n",
    "- **RMSE:** The square root of the difference between the actual and predicted values. It helps you to determine whether the predictions have any large errors, either as overestimation or underestimation.\n",
    "\n",
    "As a reminder, the models predict the number of rings of an abalone based on a set of features. These predictions are used to estimate how old an abalone is without damaging it. Each ring is equivalent to a year of life, much like the rings of a tree. The predicted values are the number of rings that the model estimates an abalone has.\n",
    "\n",
    "To start, evaluate the first variant, **Production-Model-A**, with the prediction values that were collected in the prior task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate-model-A-metrics\n",
    "df_with_labels = pd.read_csv(\"data/abalone_data_new.csv\", header=None)\n",
    "test_labels = df_with_labels.iloc[:, 0]\n",
    "labels = test_labels.to_numpy()\n",
    "print(\"The predicted values are:\\n {}\\n\".format(preds))\n",
    "print(\"The actual values are:\\n {}\\n\".format(labels))\n",
    "\n",
    "# Calculate R2\n",
    "score = r2_score(labels, preds)\n",
    "print(\"The R2 score of the current production model is {}\".format(round(score, 2)))\n",
    "\n",
    "# Calculate MAE\n",
    "score = mean_absolute_error(labels, preds)\n",
    "print(\"The Mean Absolute Error of the current production model is {}\".format(round(score, 2)))\n",
    "\n",
    "# Calculate RMSE\n",
    "score = np.sqrt(mean_absolute_error(labels, preds))\n",
    "print(\"The Root Mean Squared Error of the current production model is {}\".format(round(score, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully evaluated the current production model. Your task is to use these metrics to determine whether the new model improves these scores. If the new model is better than the production model, the R2 score increases, the MAE decreases, and the RMSE decreases. You evaluate the difference between the model metrics later in the task.\n",
    "\n",
    "To see your new model's predictions, invoke the **New-Model-B** variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions2 = \"\"\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "with open(\"data/abalone_data_test.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"text/csv\",\n",
    "            Body=payload,\n",
    "            TargetVariant=variant2[\"VariantName\"],\n",
    "        )\n",
    "        predictions2 = \",\".join([predictions2, response[\"Body\"].read().decode(\"utf-8\")])\n",
    "\n",
    "# Convert the predictions to a numpy array and round the values\n",
    "pred_np2 = np.fromstring(predictions2[1:], sep=\",\")\n",
    "preds2 = np.round(pred_np2)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the traffic per variant again. This time, you see that the number of invocations only incremented for *New-Model-B* because all of the invocations were targeted at that variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot-model-B-metrics\n",
    "time.sleep(20)  # let metrics catch up\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have collected a list of predicted values for the second model, evaluate the R2 score, MAE, and RMSE metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate-model-B-metrics\n",
    "df_with_labels = pd.read_csv(\"data/abalone_data_new.csv\", header=None)\n",
    "test_labels = df_with_labels.iloc[:, 0]\n",
    "labels = test_labels.to_numpy()\n",
    "print(\"The predicted values are:\\n {}\\n\".format(preds2))\n",
    "print(\"The actual values are:\\n {}\\n\".format(labels))\n",
    "\n",
    "# Calculate R2\n",
    "score = r2_score(labels, preds2)\n",
    "print(\"The R2 score of the new model is {}\".format(round(score, 2)))\n",
    "\n",
    "# Calculate MAE\n",
    "score = mean_absolute_error(labels, preds2)\n",
    "print(\"The Mean Absolute Error of the new model is {}\".format(round(score, 2)))\n",
    "\n",
    "# Calculate RMSE\n",
    "score = np.sqrt(mean_absolute_error(labels, preds2))\n",
    "print(\"The Root Mean Squared Error of the new model is {}\".format(round(score, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not performing better than the current production model. The R2 score is lower, the MAE is higher, and the RMSE is higher. Once you have a new model to test, you can edit the endpoint configuration to deploy a new model before shifting production traffic to it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully configured an A/B testing strategy, tested model variants, and reviewed the performance of the model variants.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with **Task 3**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
